{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8a751a",
   "metadata": {},
   "source": [
    "## SHREC 2022 - PRIMITIVE FITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f27b27",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Preliminaries](#prelims)\n",
    "* [Data Loading](#dl)\n",
    "* [Dataset](#dset)\n",
    "* [Baseline Model](#bmodel)\n",
    "* [Losses](#losses)\n",
    "* [Training Loop](#tloop)\n",
    "* [Sources](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0237d",
   "metadata": {},
   "source": [
    "## Preliminaries <a class=\"anchor\" id=\"prelims\"></a>\n",
    "\n",
    "The _\"SHREC 2022: Fitting and recognition of simple geometric primitives on point clouds\"_ track poses the challenge of recovering primitive shape parameters from 3d point clouds. The data consists of unordered points sampled from various primitives, possibly by adding some form of perturbation like noise, dropout, deformation etc. The set of all possible primitives and their parameters are as follows:\n",
    "\n",
    "  * **Plane**, represented as its normal vector and a point sampled from the surface of the plane,\n",
    "  * **Cylinder**, represented as its radius, rotation axis and a point sampled along said axis,\n",
    "  * **Sphere**, represented as its radius and center,\n",
    "  * **Cone**, represented as the rotational axis, half the aperture (the angle $\\theta$ between the axis and any generatrix line) as well as a vertex.\n",
    "  * **Torus**, represented as the major and minor radii, the rotational axis and the center.\n",
    "\n",
    "The task is to build a framework that, given a point cloud, predicts the parameters of the primitive it was sampled from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14512b6",
   "metadata": {},
   "source": [
    "### Data Loading <a class=\"anchor\" id=\"dl\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a444543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "import einops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42772dea",
   "metadata": {},
   "source": [
    "Having imported the necessary libary for displaying and manipulating the data as tensors, let us proceed to create appropriate functions for loading, conversions and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "857c2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point_cloud(fname):\n",
    "    \n",
    "    file = open(fname)\n",
    "    points = []\n",
    "    \n",
    "    for line in file.readlines():\n",
    "        pts = torch.Tensor(list(map(float, line.split(\",\"))))\n",
    "        points.append(pts)\n",
    "    \n",
    "    return einops.rearrange(points, \"n d -> n d\")\n",
    "\n",
    "def tensor_to_o3d(pcloud):\n",
    "    \n",
    "    #sanity check\n",
    "    assert pcloud.dim() == 2\n",
    "    assert pcloud.shape[1] == 3\n",
    "    \n",
    "    #converting to numpy and removing device and associated gradients\n",
    "    pcloud = pcloud.cpu().detach().numpy()\n",
    "    \n",
    "    #converting to open3d's data structures\n",
    "    pcloud = o3d.utility.Vector3dVector(pcloud)\n",
    "    pcloud = o3d.geometry.PointCloud(pcloud)\n",
    "    \n",
    "    return pcloud\n",
    "\n",
    "#Displays a given point cloud using WebGL functionality\n",
    "def show_point_cloud_o3d(pcloud):\n",
    "    \n",
    "    if isinstance(pcloud, torch.Tensor):\n",
    "        pcloud = tensor_to_o3d(pcloud)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcloud])\n",
    "\n",
    "#Displays a given point cloud using open3d's JVisualizer\n",
    "def show_point_cloud_jupyter(pcloud):\n",
    "    \n",
    "    if isinstance(pcloud, torch.Tensor):\n",
    "        pcloud = tensor_to_o3d(pcloud)\n",
    "    \n",
    "    o3d.web_visualizer.draw(pcloud)\n",
    "\n",
    "def show_point_cloud_with_normals_o3d(pcloud, radius=0.1, max_nn=30):\n",
    "    \n",
    "    if isinstance(pcloud, torch.Tensor):\n",
    "        pcloud = tensor_to_o3d(pcloud)\n",
    "    \n",
    "    pcloud.estimate_normals(\n",
    "    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn))\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcloud], point_show_normal = True)\n",
    "    \n",
    "    \n",
    "def category_indices(base_path, train_folder, gt_folder, train_prefix=None, gt_prefix=None, format=\".txt\"):\n",
    "    \n",
    "    '''\n",
    "        This function assumes the following file structure:\n",
    "        \n",
    "        base_path\n",
    "        -train_folder\n",
    "            -train_prefix + {i} + .txt\n",
    "        -gt_folder\n",
    "            -gt_prefix + {i} + .txt\n",
    "            \n",
    "        And the following file contents:\n",
    "        \n",
    "        GT:\n",
    "            a single integer corresponding to a category\n",
    "        Train:\n",
    "            N lines containing 3 comma-separated floats corresponding to point coordinates\n",
    "    '''\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    #\n",
    "    train_prefix = train_prefix or train_folder \n",
    "    gt_prefix = gt_prefix or gt_folder \n",
    "    \n",
    "    #\n",
    "    train_path = os.path.join(base_path, train_folder)\n",
    "    gt_path = os.path.join(base_path, gt_folder)\n",
    "    \n",
    "    #\n",
    "    gt_file = lambda i : os.path.join(gt_path, gt_prefix + str(i) + format)\n",
    "    train_file = lambda i : os.path.join(train_path, train_prefix + str(i) + format)\n",
    "    \n",
    "    #\n",
    "    categories = {}\n",
    "    \n",
    "    #\n",
    "    samples = os.listdir(train_path)\n",
    "    N = len(samples)\n",
    "    \n",
    "    for i in tqdm(range(1, N+1)):\n",
    "        with open(gt_file(i)) as GT:\n",
    "            \n",
    "            cat = GT.readline()[0]\n",
    "            if cat not in categories.keys(): \n",
    "                categories[cat] = [i]\n",
    "            else:\n",
    "                categories[cat].append(i)\n",
    "    \n",
    "    save_path = os.path.join(base_path,\"indices.txt\");\n",
    "    \n",
    "    with open(save_path, \"w\") as F:\n",
    "        for key in categories.keys():\n",
    "            F.write(\",\".join(map(str, categories[key])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "460df72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▏                                                                                                                                                         | 925/46000 [00:00<00:04, 9205.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding category 1\n",
      "adding category 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▌                                                                                                                                               | 3692/46000 [00:00<00:04, 9189.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding category 4\n",
      "adding category 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████████▊                                                                                                                                         | 5531/46000 [00:00<00:04, 8451.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding category 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46000/46000 [00:05<00:00, 8225.98it/s]\n"
     ]
    }
   ],
   "source": [
    "sample = 32004\n",
    "#path = f\"./data/point_clouds/pointCloud{sample}.txt\"\n",
    "path = f\"C:\\\\Users\\\\vlassis\\\\Desktop\\\\phd\\\\datasets\\\\shrec2022\\\\training\\\\pointCloud\\\\pointCloud{sample}.txt\"\n",
    "\n",
    "base = \"C:\\\\Users\\\\vlassis\\\\Desktop\\\\phd\\\\datasets\\\\shrec2022\\\\training\"\n",
    "category_indices(base, \"pointCloud\", \"GTpointCloud\")\n",
    "\n",
    "#pcloud = parse_point_cloud(path)\n",
    "#show_point_cloud_o3d(pcloud)\n",
    "#show_point_cloud_with_normals_o3d(pcloud, radius=1)\n",
    "#segment_plane_o3d(pcloud)\n",
    "#show_point_cloud_jupyter(pcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c4391",
   "metadata": {},
   "source": [
    "## Dataset <a class=\"anchor\" id=\"dset\"></a>\n",
    "\n",
    "For a learning approach to this problem, we are going to need a dataset object and a dataloader that can be iterated. To do that we are going to be using the parser we created earlier as well as pytorch's `Dataset` class as a template. The data for this problem is unfortunately highly irregular, even if the task at hand seems easy at first glance.\n",
    "\n",
    "There are 5 different types of primitives, each with its own set of parameters. The parameters themselves can have wildly different values which are had for a typical neural network to predict. Not only that, but the length of each set of parameters is different for each primitive, not allowing a \"normal\" representation of the labels.\n",
    "\n",
    "The following dataset class will return the data and labels as a dictionary. The labels are their own dictionary, containing a string that specifies the type of primitive, its individual parameters as key-value pairs (for example `\"radius\" : 2.18`) and a torch tensor containing all of the parameters as one.\n",
    "\n",
    "Naturally, a set of transformations are also included. A particularly important one is the unit-sphere normalization, which makes sure each point vector in the point cloud has a maximum length of one. This is accomplished by dividing the coordinates by the largest point vector's length. At this step it is important to save that normalization factor for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fdbc6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHREC2022Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, train=True, valid=False, valid_split=0.2):\n",
    "        \n",
    "        self.path = os.path.join(path, \"training\" if train else \"test\")\n",
    "        self.pc_prefix = \"pointCloud\"\n",
    "        self.gt_prefix = \"GTpointCloud\"\n",
    "        self.format = \".txt\"\n",
    "        self.valid = valid if train else False\n",
    "        self.size = 0 if train else len(os.listdir(self.path))\n",
    "        \n",
    "        #check if an existing train-validation split matches the one given\n",
    "        split_info_file = path + \"training\\\\split_info.txt\"\n",
    "        self.t_savefile = path + \"training\\\\train_split.txt\"\n",
    "        self.v_savefile = path + \"training\\\\valid_split.txt\"\n",
    "        if os.path.exists(split_info_file):\n",
    "            with open(split_info_file) as F:\n",
    "                v, vsize, tsize = list(map(float, F.readline().split(',')))\n",
    "\n",
    "                if v == valid_split:\n",
    "                    print(\"Specified split already exists. Using the existing one.\")\n",
    "                    self.size = int(vsize if self.valid else tsize)\n",
    "                    return\n",
    "        \n",
    "        if train:\n",
    "            print(\"Creating a new train-validation split.\")\n",
    "            import random\n",
    "            with open(path + \"training\\\\indices.txt\") as F, open(self.t_savefile, \"w\") as T,\\\n",
    "                open(self.v_savefile, \"w\") as V, open(split_info_file, \"w\") as I:\n",
    "\n",
    "                lines = F.readlines()\n",
    "                cat_sz = len(lines[0].split(\",\"))\n",
    "                train_sz = int(cat_sz * (1-valid_split))\n",
    "\n",
    "                v_indices = []\n",
    "                t_indices = []\n",
    "\n",
    "                for line in lines:\n",
    "                    line = list(map(int, line.split(\",\")))\n",
    "                    random.shuffle(line)\n",
    "                    v_indices = v_indices + line[train_sz:]\n",
    "                    t_indices = t_indices + line[:train_sz]\n",
    "\n",
    "                self.size = len(v_indices) if valid else len(t_indices)\n",
    "                T.write(\"\\n\".join(map(str, t_indices)))\n",
    "                V.write(\"\\n\".join(map(str, v_indices)))\n",
    "                \n",
    "                I.write(str(valid_split)+','+str(len(v_indices))+','+str(len(t_indices)))\n",
    "\n",
    "        \n",
    "    def parse_point_cloud(self, fname):\n",
    "    \n",
    "        file = open(fname)\n",
    "        points = []\n",
    "\n",
    "        for line in file.readlines():\n",
    "            pts = torch.Tensor(list(map(float, line.split(\",\"))))\n",
    "            points.append(pts)\n",
    "\n",
    "        file.close()\n",
    "        \n",
    "        return einops.rearrange(points, \"n d -> n d\")\n",
    "    \n",
    "    def parse_label(self, fname):\n",
    "        \n",
    "        file = open(fname)\n",
    "        \n",
    "        #assigning a distinct function to handle each type of primitive\n",
    "        handlers ={\n",
    "                   \"1\": self.parse_plane,\n",
    "                   \"2\": self.parse_cylinder,\n",
    "                   \"3\": self.parse_sphere,\n",
    "                   \"4\": self.parse_cone,\n",
    "                   \"5\": self.parse_torus\n",
    "                  }\n",
    "        \n",
    "        #parsing the contents of the file. The first character corresponds to a specific type of primitive\n",
    "        contents =  file.readlines()\n",
    "        \n",
    "        file.close()\n",
    "        \n",
    "        #handling the primitive and returning the label\n",
    "        return handlers[contents[0][0]](contents)\n",
    "    \n",
    "    def parse_plane(self, lines):\n",
    "        \n",
    "        normal = torch.Tensor(list(map(float, lines[1:4])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[4:])))\n",
    "        data = torch.Tensor(list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"plane\", \"class\": 0, \"vertex\": vertex, \"normal\":normal, \"data\": data}\n",
    "    \n",
    "    def parse_cylinder(self, lines):\n",
    "        \n",
    "        radius = float(lines[1])\n",
    "        axis = torch.Tensor(list(map(float, lines[2:5])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[5:])))\n",
    "        data = torch.Tensor(list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"cylinder\", \"class\": 1, \"radius\": radius, \"axis\": axis, \"vertex\": vertex, \"data\": data}\n",
    "    \n",
    "    def parse_sphere(self, lines):\n",
    "        \n",
    "        radius = float(lines[1])\n",
    "        center = torch.Tensor(list(map(float, lines[2:])))\n",
    "        data = torch.Tensor(list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"sphere\", \"class\": 2, \"radius\": radius, \"center\": center, \"data\": data}\n",
    "    \n",
    "    def parse_cone(self, lines):\n",
    "        \n",
    "        angle = float(lines[1])\n",
    "        axis = torch.Tensor(list(map(float, lines[2:5])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[5:])))\n",
    "        data = torch.Tensor(list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"cone\", \"class\": 3, \"angle\": angle, \"axis\": axis, \"vertex\": vertex, \"data\": data}\n",
    "    \n",
    "    def parse_torus(self, lines):\n",
    "        \n",
    "        major_radius = float(lines[1])\n",
    "        minor_radius = float(lines[2])\n",
    "        axis = torch.Tensor(list(map(float, lines[3:6])))\n",
    "        center = torch.Tensor(list(map(float, lines[6:])))\n",
    "        data = torch.Tensor(list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"torus\", \"class\": 4, \"major_radius\": major_radius, \"minor_radius\": minor_radius, \"axis\": axis, \"center\": center, \"data\": data}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        with open(self.v_savefile if self.valid else self.t_savefile, \"r\") as F:\n",
    "            index = F.readlines()[index]\n",
    "            index = int(index) if '\\n' not in index else int(index[:-1])\n",
    "         \n",
    "        \n",
    "        #assembling the file name for the data and labels\n",
    "        pc_name = os.path.join(self.path, self.pc_prefix, self.pc_prefix + str(index) + self.format)\n",
    "        gt_name = os.path.join(self.path, self.gt_prefix, self.gt_prefix + str(index) + self.format)\n",
    "        \n",
    "        #parsing the point cloud\n",
    "        pcloud = self.parse_point_cloud(pc_name)\n",
    "        label = self.parse_label(gt_name)\n",
    "        \n",
    "        data = {\"x\": pcloud, \"y\": label}\n",
    "        \n",
    "        return self.transform(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.size\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \n",
    "        return self.unit_sphere_normalize(data)\n",
    "        \n",
    "    def unit_sphere_normalize(self, x):\n",
    "        \n",
    "        max_norm = (x[\"x\"]*x[\"x\"]).sum(-1).max().sqrt()\n",
    "        x[\"x\"] /= max_norm\n",
    "        \n",
    "        x[\"norm_factor\"] = max_norm\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def batch_collate_fn(batch_list):\n",
    "    \n",
    "    max_sz = int(torch.Tensor([item['x'].shape[0] for item in batch_list]).max().item())\n",
    "    pad = torch.zeros(1, 3)\n",
    "    \n",
    "    print(max_sz)\n",
    "    x = torch.stack([torch.cat((item['x'], pad.repeat((max_sz - item['x'].shape[0], 1))), dim=0) for item in batch_list])\n",
    "    \n",
    "    return {\n",
    "           \"x\":   x,\n",
    "           \"y\":   torch.Tensor([item['y']['class'] for item in batch_list]),\n",
    "           #\"z\":   torch.stack([item['y']['data'] for item in batch_list]),\n",
    "           \"w\":   [item['y'] for item in batch_list] \n",
    "    }\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a4ea049e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new train-validation split.\n",
      "Specified split already exists. Using the existing one.\n",
      "9200\n",
      "36800\n"
     ]
    }
   ],
   "source": [
    "#dataset contains 9200 samples from each class\n",
    "path = f\"C:\\\\Users\\\\vlassis\\\\Desktop\\\\phd\\\\datasets\\\\shrec2022\\\\\"\n",
    "t_dataset = SHREC2022Dataset(path, train=True, valid=True, valid_split=0.2)\n",
    "v_dataset = SHREC2022Dataset(path, train=True, valid=False, valid_split=0.2)\n",
    "\n",
    "sample1 = t_dataset[0]\n",
    "sample2 = v_dataset[0]\n",
    "# show_point_cloud_o3d(sample1['x'])\n",
    "# show_point_cloud_o3d(sample2['x'])\n",
    "print(len(t_dataset))\n",
    "print(len(v_dataset))\n",
    "\n",
    "# path = f\"C:\\\\Users\\\\vlassis\\\\Desktop\\\\phd\\\\shrec2022\\\\\"\n",
    "# plane_sample = 0\n",
    "# cylinder_sample = 1000\n",
    "# sphere_sample = 3000\n",
    "# cone_sample = 2000\n",
    "# torus_sample = 4000\n",
    "\n",
    "# dataset = SHREC2022Dataset(path, train=True)\n",
    "# batch = [dataset[0], dataset[1000], dataset[2000], dataset[3000], dataset[4000]]\n",
    "# out = batch_collate_fn(batch)\n",
    "\n",
    "# print(dataset[0])\n",
    "# print(dataset[1000])\n",
    "# print(dataset[2000])\n",
    "# print(dataset[3000])\n",
    "# print(dataset[4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53b92f",
   "metadata": {},
   "source": [
    "### Baseline Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "For the base model we will be testing out the PointNet we implemented in <a href=\"../../implementations/notebooks/pointnet.ipynb\">this</a> notebook. Knowing the data has been affected by dropouts there are bound to be point clouds with considerably different cardinality. PointNet can consume point clouds of any number of input points, it is unnaffected by permutations and it is resistant to transformations such as rotation. This makes it suitable for a baseline model before we can move on to a more complex architecture.\n",
    "\n",
    "Our implementation of PointNet outputs $k$ unnormalized scores which can be used for k-class classification. Since our data consists of 5 distinct primitives, each with its own set of parameters we are going to use PointNet as a feature extractor and feed the $k$ outputs to 5 regression heads, each one responsible for predicting a different set of parameters. Since we have no way of knowing in advance which primitive will be predicted, but we do know that each data sample contains exactly one, we have several choices:\n",
    "\n",
    "  * Stack a 6th linear head on top of the model, with 5 outputs, responsible for classifying the input shape into one of the 5 categories. We can then predict parameters for all types of primitives, but only use the set corresponding to the classified primitive.\n",
    "  \n",
    "  * We can se all 5 of the regressors, and measure the distance between the input shape and each one of the predicted primitives. Then we choose the primitive that yielded the lowest distance as the correct one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b015e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../implementations/notebooks/pointnet.ipynb\n",
    "\n",
    "regressor_outputs = {\n",
    "    \"plane\": 6, \"cylinder\": 7, \"cone\": 7,\n",
    "    \"sphere\": 4, \"torus\": 8\n",
    "}\n",
    "\n",
    "class Regressor(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        self.reg = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, out_channels),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(in_channels, in_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.reg(x)\n",
    "\n",
    "class BaselineModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, feat_vector_dim):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        \n",
    "        self.pointnet = PointNet(in_channels, feat_vector_dim)\n",
    "        \n",
    "        self.reg_plane    = Regressor(feat_vector_dim, regressor_outputs[\"plane\"])\n",
    "        self.reg_cylinder = Regressor(feat_vector_dim, regressor_outputs[\"cylinder\"])\n",
    "        self.reg_cone     = Regressor(feat_vector_dim, regressor_outputs[\"cone\"])\n",
    "        self.reg_sphere   = Regressor(feat_vector_dim, regressor_outputs[\"sphere\"])\n",
    "        self.reg_torus    = Regressor(feat_vector_dim, regressor_outputs[\"torus\"])\n",
    "        self.shape_cls    = torch.nn.Linear(feat_vector_dim, len(regressor_outputs))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        feat_vec = self.pointnet(x)\n",
    "        \n",
    "        plane_params = self.reg_plane(feat_vec)\n",
    "        cylinder_params = self.reg_cylinder(feat_vec)\n",
    "        cone_params = self.reg_cone(feat_vec)\n",
    "        sphere_params = self.reg_sphere(feat_vec)\n",
    "        torus_params = self.reg_torus(feat_vec)\n",
    "        class_preds = self.shape_cls(feat_vec)\n",
    "        \n",
    "        return class_preds, (plane_params, cylinder_params, cone_params, sphere_params, torus_params)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0aa17e",
   "metadata": {},
   "source": [
    "## Losses <a class=\"anchor\" id=\"losses\"></a>\n",
    "\n",
    "Since finding an appropriate distance measure is not easy; an analytical one might not exist and a sample based one would have high computational requirements, the second implementation option is not feasible. Therefore, we choose to go with the former option, to include a classification head that chooses which primitive type the current example has been sampled from.\n",
    "\n",
    "Simply classifying the primitive correctly is not enough however, as the output primitive parameters must have sensible values as well. We must therefore employ specifically tailored regularization losses that tend to each type of parameter and force it to have approximately \"proper\" values. \n",
    "\n",
    "Let's assume, for instance, that we have correctly classified a primitive as \"plane\". Then the angle between the predicted and the actual normal of the plane must be small, and the distance of the predicted vertex from the actual plane must be low. This can be as easy as using a mean squared error criterion, but maybe more specific distance measures will yield better results. Both approaches are worth attempting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy criterion for classification\n",
    "cls_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#------------------APROACH 1----------------------\n",
    "#mean squared error criterion for the rest\n",
    "param_loss = torch.nn.MSELoss()\n",
    "\n",
    "#------------------APROACH 2----------------------\n",
    "#axis loss\n",
    "def axis_loss(ax1, ax2):\n",
    "    return torch.dot(ax1, ax2)\n",
    "\n",
    "#\n",
    "B, num_epochs = 2, 50\n",
    "path = f\"C:\\\\Users\\\\vlassis\\\\Desktop\\\\phd\\\\datasets\\\\shrec2022\\\\\"\n",
    "dataset = SHREC2022Dataset(path, train=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = B, collate_fn = batch_collate_fn, shuffle = True, drop_last = False)\n",
    "\n",
    "model = BaselineModel(3, 256).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b323bd",
   "metadata": {},
   "source": [
    "## Training Loop <a class=\"anchor\" id=\"tloop\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7323097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8099\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m pred, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m cls_loss(pred, y)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mBaselineModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     39\u001b[0m     feat_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointnet(x)\n\u001b[1;32m---> 41\u001b[0m     plane_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_plane\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     cylinder_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_cylinder(feat_vec)\n\u001b[0;32m     43\u001b[0m     cone_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_cone(feat_vec)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mRegressor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\phdenv\\lib\\site-packages\\torch\\nn\\functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[1;32m-> 1848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    \n",
    "    m_loss = 0\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        x = batch[\"x\"].cuda()\n",
    "        y = batch[\"y\"].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred, _ = model(x.permute(0,2,1))\n",
    "        \n",
    "        loss = cls_loss(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        m_loss += loss.item() / B\n",
    "        \n",
    "    m_loss /= len(dataloader)\n",
    "    \n",
    "    print(f\"epoch {i} - loss: {m_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445821a8",
   "metadata": {},
   "source": [
    "### Sources <a class=\"anchor\" id=\"refs\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
