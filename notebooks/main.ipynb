{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8a751a",
   "metadata": {},
   "source": [
    "## SHREC 2022 - PRIMITIVE FITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f27b27",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Preliminaries](#prelims)\n",
    "* [Data Loading](#dl)\n",
    "* [Dataset](#dset)\n",
    "* [Baseline Model](#bmodel)\n",
    "* [Losses](#losses)\n",
    "* [Training Loop](#tloop)\n",
    "* [Sources](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0237d",
   "metadata": {},
   "source": [
    "## Preliminaries <a class=\"anchor\" id=\"prelims\"></a>\n",
    "\n",
    "The _\"SHREC 2022: Fitting and recognition of simple geometric primitives on point clouds\"_ track poses the challenge of recovering primitive shape parameters from 3d point clouds. The data consists of unordered points sampled from various primitives, possibly by adding some form of perturbation like noise, dropout, deformation etc. The set of all possible primitives and their parameters are as follows:\n",
    "\n",
    "  * **Plane**, represented as its normal vector and a point sampled from the surface of the plane,\n",
    "  * **Cylinder**, represented as its radius, rotation axis and a point sampled along said axis,\n",
    "  * **Sphere**, represented as its radius and center,\n",
    "  * **Cone**, represented as the rotational axis, half the aperture (the angle $\\theta$ between the axis and any generatrix line) as well as a vertex.\n",
    "  * **Torus**, represented as the major and minor radii, the rotational axis and the center.\n",
    "\n",
    "The task is to build a framework that, given a point cloud, predicts the parameters of the primitive it was sampled from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14512b6",
   "metadata": {},
   "source": [
    "### Data Loading <a class=\"anchor\" id=\"dl\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a444543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "import einops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42772dea",
   "metadata": {},
   "source": [
    "Having imported the necessary libary for displaying and manipulating the data as tensors, let us proceed to create appropriate functions for loading, conversions and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857c2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point_cloud(fname):\n",
    "    \n",
    "    file = open(fname)\n",
    "    points = []\n",
    "    \n",
    "    for line in file.readlines():\n",
    "        pts = torch.Tensor(list(map(float, line.split(\",\"))))\n",
    "        points.append(pts)\n",
    "    \n",
    "    return einops.rearrange(points, \"n d -> n d\")\n",
    "\n",
    "def tensor_to_o3d(pcloud):\n",
    "    \n",
    "    #sanity check\n",
    "    assert pcloud.dim() == 2\n",
    "    assert pcloud.shape[1] == 3\n",
    "    \n",
    "    #converting to numpy and removing device and associated gradients\n",
    "    pcloud = pcloud.cpu().detach().numpy()\n",
    "    \n",
    "    #converting to open3d's data structures\n",
    "    pcloud = o3d.utility.Vector3dVector(pcloud)\n",
    "    pcloud = o3d.geometry.PointCloud(pcloud)\n",
    "    \n",
    "    return pcloud\n",
    "\n",
    "#Displays a given point cloud using WebGL functionality\n",
    "def show_point_cloud_o3d(pcloud):\n",
    "    \n",
    "    if isinstance(pcloud, torch.Tensor):\n",
    "        pcloud = tensor_to_o3d(pcloud)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcloud])\n",
    "\n",
    "#Displays a given point cloud using open3d's JVisualizer\n",
    "def show_point_cloud_jupyter(pcloud):\n",
    "    \n",
    "    if isinstance(pcloud, torch.Tensor):\n",
    "        pcloud = tensor_to_o3d(pcloud)\n",
    "    \n",
    "    o3d.web_visualizer.draw(pcloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c4391",
   "metadata": {},
   "source": [
    "## Dataset <a class=\"anchor\" id=\"dset\"></a>\n",
    "\n",
    "For a learning approach to this problem, we are going to need a dataset object and a dataloader that can be iterated. To do that we are going to be using the parser we created earlier as well as pytorch's `Dataset` class as a template. The data for this problem is unfortunately highly irregular, even if the task at hand seems easy at first glance.\n",
    "\n",
    "There are 5 different types of primitives, each with its own set of parameters. The parameters themselves can have wildly different values which are had for a typical neural network to predict. Not only that, but the length of each set of parameters is different for each primitive, not allowing a \"normal\" representation of the labels.\n",
    "\n",
    "The following dataset class will return the data and labels as a dictionary. The labels are their own dictionary, containing a string that specifies the type of primitive, its individual parameters as key-value pairs (for example `\"radius\" : 2.18`) and a torch tensor containing all of the parameters as one.\n",
    "\n",
    "Naturally, a set of transformations are also included. A particularly important one is the unit-sphere normalization, which makes sure each point vector in the point cloud has a maximum length of one. This is accomplished by dividing the coordinates by the largest point vector's length. At this step it is important to save that normalization factor for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbc6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "class SHREC2022Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path, train=True):\n",
    "        \n",
    "        self.path = os.path.join(path, \"training\" if train else \"test\")\n",
    "        self.pc_prefix = \"pointCloud\"\n",
    "        self.gt_prefix = \"GTpointCloud\"\n",
    "        self.format = \".txt\"\n",
    "        \n",
    "        self.size = len(os.listdir(os.path.join(self.path, self.pc_prefix)))\n",
    "\n",
    "        \n",
    "    def parse_point_cloud(self, fname):\n",
    "    \n",
    "        file = open(fname)\n",
    "        points = []\n",
    "\n",
    "        for line in file.readlines():\n",
    "            pts = torch.Tensor(list(map(float, line.split(\",\"))))\n",
    "            points.append(pts)\n",
    "\n",
    "        return einops.rearrange(points, \"n d -> n d\")\n",
    "    \n",
    "    def parse_label(self, fname):\n",
    "        \n",
    "        file = open(fname)\n",
    "        \n",
    "        #assigning a distinct function to handle each type of primitive\n",
    "        handlers ={\n",
    "                   \"1\": self.parse_plane,\n",
    "                   \"2\": self.parse_cylinder,\n",
    "                   \"3\": self.parse_sphere,\n",
    "                   \"4\": self.parse_cone,\n",
    "                   \"5\": self.parse_torus\n",
    "                  }\n",
    "        \n",
    "        #parsing the contents of the file. The first character corresponds to a specific type of primitive\n",
    "        contents =  file.readlines()\n",
    "        \n",
    "        #handling the primitive and returning the label\n",
    "        return handlers[contents[0][0]](contents)\n",
    "    \n",
    "    def parse_plane(self, lines):\n",
    "        \n",
    "        normal = torch.Tensor(list(map(float, lines[1:4])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[4:])))\n",
    "        data = torch.Tensor([0] + list(map(float, lines[1:])) + [-1, -1])\n",
    "    \n",
    "        return {\"type\": \"plane\", \"class\": 0, \"vertex\": vertex, \"normal\":normal, \"data\": data}\n",
    "    \n",
    "    def parse_cylinder(self, lines):\n",
    "        \n",
    "        radius = float(lines[1])\n",
    "        axis = torch.Tensor(list(map(float, lines[2:5])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[5:])))\n",
    "        data = torch.Tensor([1] + list(map(float, lines[1:])) + [-1])\n",
    "    \n",
    "        return {\"type\": \"cylinder\", \"class\": 1, \"radius\": radius, \"axis\": axis, \"vertex\": vertex, \"data\": data}\n",
    "    \n",
    "    def parse_sphere(self, lines):\n",
    "        \n",
    "        radius = float(lines[1])\n",
    "        center = torch.Tensor(list(map(float, lines[2:])))\n",
    "        data = torch.Tensor([2] + list(map(float, lines[1:])) + [-1]*4)\n",
    "    \n",
    "        return {\"type\": \"sphere\", \"class\": 2, \"radius\": radius, \"center\": center, \"data\": data}\n",
    "    \n",
    "    def parse_cone(self, lines):\n",
    "        \n",
    "        angle = float(lines[1])\n",
    "        axis = torch.Tensor(list(map(float, lines[2:5])))\n",
    "        vertex = torch.Tensor(list(map(float, lines[5:])))\n",
    "        data = torch.Tensor([3] + list(map(float, lines[1:])) + [-1])\n",
    "    \n",
    "        return {\"type\": \"cone\", \"class\": 3, \"angle\": angle, \"axis\": axis, \"vertex\": vertex, \"data\": data}\n",
    "    \n",
    "    def parse_torus(self, lines):\n",
    "        \n",
    "        major_radius = float(lines[1])\n",
    "        minor_radius = float(lines[2])\n",
    "        axis = torch.Tensor(list(map(float, lines[3:6])))\n",
    "        center = torch.Tensor(list(map(float, lines[6:])))\n",
    "        data = torch.Tensor([4] + list(map(float, lines[1:])))\n",
    "    \n",
    "        return {\"type\": \"torus\", \"class\": 4, \"major_radius\": major_radius, \"minor_radius\": minor_radius, \"axis\": axis, \"center\": center, \"data\": data}\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #adding 1 because the files are not 0-indexed\n",
    "        index += 1\n",
    "        \n",
    "        #assembling the file name for the data and labels\n",
    "        pc_name = os.path.join(self.path, self.pc_prefix, self.pc_prefix + str(index) + self.format)\n",
    "        gt_name = os.path.join(self.path, self.gt_prefix, self.gt_prefix + str(index) + self.format)\n",
    "        \n",
    "        #parsing the point cloud\n",
    "        pcloud = self.parse_point_cloud(pc_name)\n",
    "        label = self.parse_label(gt_name)\n",
    "        \n",
    "        #data = {\"x\": pcloud, \"y\": label['data']}\n",
    "        data = Data(x=pcloud, y=label['data'].unsqueeze(0))\n",
    "        \n",
    "        return self.transform(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.size\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \n",
    "        return self.unit_sphere_normalize(data)\n",
    "        \n",
    "    def unit_sphere_normalize(self, x):\n",
    "        \n",
    "        max_norm = (x[\"x\"]*x[\"x\"]).sum(-1).max().sqrt()\n",
    "        x[\"x\"] /= max_norm\n",
    "        \n",
    "        x[\"norm_factor\"] = max_norm\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def batch_collate_fn(batch_list):\n",
    "    \n",
    "    max_sz = int(torch.Tensor([item['x'].shape[0] for item in batch_list]).max().item())\n",
    "    pad = torch.zeros(1, 3)\n",
    "    \n",
    "    print(max_sz)\n",
    "    x = torch.stack([torch.cat((item['x'], pad.repeat((max_sz - item['x'].shape[0], 1))), dim=0) for item in batch_list])\n",
    "    \n",
    "    return {\n",
    "           \"x\":   x,\n",
    "           \"y\":   torch.Tensor([item['y']['class'] for item in batch_list]),\n",
    "           #\"z\":   torch.stack([item['y']['data'] for item in batch_list]),\n",
    "           \"w\":   [item['y'] for item in batch_list] \n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ea049e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[51696, 3], y=[16, 9], norm_factor=[16], batch=[51696], ptr=[17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "path = \"/home/ioannis/Desktop/programming/data/SHREC/SHREC2022/dataset\"\n",
    "dataset = SHREC2022Dataset(path, train=True)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True )\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53b92f",
   "metadata": {},
   "source": [
    "### Baseline Model <a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "For the base model we will be testing out the PointNet we implemented in <a href=\"../../implementations/notebooks/pointnet.ipynb\">this</a> notebook. Knowing the data has been affected by dropouts there are bound to be point clouds with considerably different cardinality. PointNet can consume point clouds of any number of input points, it is unnaffected by permutations and it is resistant to transformations such as rotation. This makes it suitable for a baseline model before we can move on to a more complex architecture.\n",
    "\n",
    "Our implementation of PointNet outputs $k$ unnormalized scores which can be used for k-class classification. Since our data consists of 5 distinct primitives, each with its own set of parameters we are going to use PointNet as a feature extractor and feed the $k$ outputs to 5 regression heads, each one responsible for predicting a different set of parameters. Since we have no way of knowing in advance which primitive will be predicted, but we do know that each data sample contains exactly one, we have several choices:\n",
    "\n",
    "  * Stack a 6th linear head on top of the model, with 5 outputs, responsible for classifying the input shape into one of the 5 categories. We can then predict parameters for all types of primitives, but only use the set corresponding to the classified primitive.\n",
    "  \n",
    "  * We can se all 5 of the regressors, and measure the distance between the input shape and each one of the predicted primitives. Then we choose the primitive that yielded the lowest distance as the correct one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b015e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_outputs = {\n",
    "    \"plane\": 6, \"cylinder\": 7, \"cone\": 7,\n",
    "    \"sphere\": 4, \"torus\": 8\n",
    "}\n",
    "\n",
    "class Regressor(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Regressor, self).__init__()\n",
    "        \n",
    "        self.reg = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, out_channels),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(in_channels, in_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.reg(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990dc9a",
   "metadata": {},
   "source": [
    "# PointNet backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f88f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import math\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "\n",
    "#Convenience module, includes a sharedMLP (conv1d or fully connected)\n",
    "#Includes batch normalization and relu non-linearity if specified\n",
    "class SharedMLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, conv = False, include_bn = True, include_relu = True):\n",
    "        super(SharedMLP, self).__init__()\n",
    "        \n",
    "        modules = [torch.nn.Conv1d(in_channels, out_channels, 1)] if conv else [torch.nn.Linear(in_channels, out_channels)]\n",
    "        \n",
    "        if include_bn:\n",
    "            modules.append(torch.nn.BatchNorm1d(out_channels))\n",
    "            \n",
    "        if include_relu:\n",
    "            modules.append(torch.nn.ReLU())\n",
    "            \n",
    "        self.net = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.net(x)\n",
    "\n",
    "    \n",
    "#PointNet architecture\n",
    "class PointNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(PointNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.k = num_classes\n",
    "                        \n",
    "        #Shared MLP layers 3->64, 64->64\n",
    "        self.seq1 = torch.nn.Sequential(\n",
    "            SharedMLP(3, 64),\n",
    "            SharedMLP(64, 64),\n",
    "        )\n",
    "                        \n",
    "        \n",
    "        self.seq2 = torch.nn.Sequential(\n",
    "            #Shared MLP layers 64->64, 64->128, 128->1024\n",
    "            SharedMLP(64, 64),\n",
    "            SharedMLP(64, 128),\n",
    "            SharedMLP(128, 1024),\n",
    "        )\n",
    "        \n",
    "        self.seq3 = torch.nn.Sequential(\n",
    "            #Linear layers\n",
    "            SharedMLP(1024, 512, conv=False),\n",
    "            SharedMLP(512, 256, conv=False),\n",
    "            nn.Dropout(p=0.3),\n",
    "            SharedMLP(256, self.k, conv=False, include_bn=False, include_relu=False)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Input: \n",
    "        #    x -> Tensor (B, F, N)\n",
    "        #\n",
    "        #Output:\n",
    "        #    x  -> Tensor(B, k)\n",
    "        #    t1 -> Tensor(B, 3, 3)\n",
    "        #    t2 -> Tensor(B, 64, 64)\n",
    "            \n",
    "        #applying the input transform\n",
    "        \n",
    "        #applying shared mlp\n",
    "        f = self.seq1(x.x)\n",
    "                \n",
    "        #applying shared mlp\n",
    "        f = self.seq2(f)\n",
    "        \n",
    "        f = gnn.global_max_pool(f, x.batch)\n",
    "        \n",
    "        f = self.seq3(f)\n",
    "                \n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b323bd",
   "metadata": {},
   "source": [
    "## Training Loop <a class=\"anchor\" id=\"tloop\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7323097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2875/2875 [11:59<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - loss: 0.07429158687591553\n",
      "---- accuracy 0.5091738700866699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2875/2875 [11:43<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - loss: 0.06451764702796936\n",
      "---- accuracy 0.5784565210342407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1903/2875 [07:28<03:48,  4.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d6f6facf35a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mm_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "#cross entropy criterion for classification\n",
    "cls_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "param_loss = torch.nn.MSELoss()\n",
    "\n",
    "num_epochs = 100\n",
    "model = PointNet(3, 5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    m_loss = 0\n",
    "    acc = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        \n",
    "        batch = batch.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        labels = batch.y[:, 0].long()\n",
    "        \n",
    "        loss = cls_loss(pred, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        m_loss += loss.item() / (batch.batch[-1]+1)\n",
    "        \n",
    "        acc += (torch.max(pred, dim=-1).indices == labels).sum() / (batch.batch[-1]+1)\n",
    "        \n",
    "    m_loss /= len(train_loader)\n",
    "    acc /= len(train_loader)\n",
    "    \n",
    "    print(f\"epoch {i} - loss: {m_loss}\")\n",
    "    print(f\"---- accuracy {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90abba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Data analytics (number of point clouds in each class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445821a8",
   "metadata": {},
   "source": [
    "### Sources <a class=\"anchor\" id=\"refs\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
